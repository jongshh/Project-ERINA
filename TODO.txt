**L.T.M (Long-Term Memory Module)**

1. Create an array in `data/erina_long-term-memory.Json` that lists each characteristic (appearance, personality, acquaintances, likes, dislikes, etc.).
2. After sufficient conversations (about 15 times), the L.T.M generation model reads the conversation logs from `data/erina_short_term_memory` to extract characteristics such as appearance, personality, acquaintances, etc., from the last 15 interactions, and outputs it in the specified format of the prompt (L.T.M.py).

   ```python
   LMTmodel = '''
   FROM rolandroland/llama3.1-uncensored
   SYSTEM: 
   '''

   ollama.create(model='LMT', modelfile=LMTmodel)

   ollama.generate(model='LMT', prompt=context from 'erina_short_term_memory')
   ```

3. The exported data is added to each array, with checks performed to ensure no duplicates are added during this process.
4. The data stored in this way will be referenced by the ERINA model when generating conversations. Repeat.

**Additional Idea:** Decaying System? Delete old long-term memories. (However, core elements like personality should be exceptions. For forgettable elements like acquaintances, allow them to be forgotten based on the order they were stored.)